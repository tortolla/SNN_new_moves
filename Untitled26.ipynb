{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMH1XGZ7ASH",
        "outputId": "0bd9850f-320a-4efd-92c8-d8ccd0ca4d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hTXD3Wl7Uek",
        "outputId": "fa331670-da11-48fd-99bb-a77e8c390315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting brian2genn\n",
            "  Downloading Brian2GeNN-1.7.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/76.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brian2<2.6,>=2.5.0.2 (from brian2genn)\n",
            "  Downloading Brian2-2.5.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=61 in /usr/local/lib/python3.10/dist-packages (from brian2genn) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (1.25.2)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (3.0.10)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (1.12.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (3.1.2)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (3.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brian2<2.6,>=2.5.0.2->brian2genn) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7->brian2<2.6,>=2.5.0.2->brian2genn) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.2->brian2<2.6,>=2.5.0.2->brian2genn) (1.3.0)\n",
            "Installing collected packages: brian2, brian2genn\n",
            "Successfully installed brian2-2.5.4 brian2genn-1.7.0\n",
            "Requirement already satisfied: brian2 in /usr/local/lib/python3.10/dist-packages (2.5.4)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.25.2)\n",
            "Requirement already satisfied: cython>=0.29 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.0.10)\n",
            "Requirement already satisfied: sympy>=1.2 in /usr/local/lib/python3.10/dist-packages (from brian2) (1.12.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.2)\n",
            "Requirement already satisfied: jinja2>=2.7 in /usr/local/lib/python3.10/dist-packages (from brian2) (3.1.4)\n",
            "Requirement already satisfied: setuptools>=61 in /usr/local/lib/python3.10/dist-packages (from brian2) (67.7.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from brian2) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.7->brian2) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.2->brian2) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install brian2genn\n",
        "!pip install brian2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PmC3nls7Wtw"
      },
      "outputs": [],
      "source": [
        "import brian2genn\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from brian2 import *\n",
        "import brian2.numpy_ as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import time\n",
        "import random\n",
        "from brian2 import *\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import brian2genn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h29SUi9Y7axI"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "def append_to_file(text, file_path):\n",
        "    \"\"\"\n",
        "    Добавляет строку в конец указанного файла.\n",
        "\n",
        "    Args:\n",
        "    text (str): Строка для добавления в файл.\n",
        "    file_path (str): Путь к файлу, в который добавляется строка.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    with open(file_path, 'a', encoding='utf-8') as file:\n",
        "        file.write(text + '\\n')  # Добавляет текст и новую строку в конец файла"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwmasOki7dvO",
        "outputId": "b25f2294-1ef8-4b72-d03d-251d43c989f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500 50 500\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def load_and_combine_data(file_paths):\n",
        "    all_data = []\n",
        "    all_labels = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        # Считываем данные\n",
        "        data = np.genfromtxt(file_path, delimiter='\\t', dtype=None, encoding=None)\n",
        "\n",
        "        # Фильтруем данные, разделяя изображения и метки\n",
        "        filtered_data = []\n",
        "        filtered_labels = []\n",
        "        for i in range(0, len(data), 12):\n",
        "            filtered_data.append(data[i:i+11])\n",
        "            filtered_labels.append(data[i+11][0])  # Предполагаем, что метка - это первый элемент следующей строки\n",
        "\n",
        "        # Добавляем считанные данные и метки в общие списки\n",
        "        all_data.extend(filtered_data)\n",
        "        all_labels.extend(filtered_labels)\n",
        "\n",
        "    # Преобразуем списки в массивы NumPy\n",
        "    all_data = np.array(all_data)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Перемешиваем данные\n",
        "    indices = np.arange(len(all_data))\n",
        "    np.random.shuffle(indices)\n",
        "    all_data = all_data[indices]\n",
        "    all_labels = all_labels[indices]\n",
        "\n",
        "    # Разделяем на обучающую и тестовую выборки\n",
        "    train_size = int(0.8 * len(all_data))\n",
        "\n",
        "    x_train = all_data[:train_size]\n",
        "    y_train = all_labels[:train_size]\n",
        "    x_test = all_data[train_size:]\n",
        "    y_test = all_labels[train_size:]\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "\n",
        "# Пример использования функции\n",
        "file_paths = ['/content/drive/MyDrive/SNN_neuro /square.csv', '/content/drive/MyDrive/SNN_neuro /triangle.csv', '/content/drive/MyDrive/SNN_neuro /circle.csv']\n",
        "(x_train, y_train), (x_test, y_test) = load_and_combine_data(file_paths)\n",
        "\n",
        "\n",
        "x_train = x_train[0:500, :, :]\n",
        "x_test = x_test[0:50, :, :]\n",
        "\n",
        "y_train = y_train[0:500]\n",
        "y_test = y_test[0:50]\n",
        "\n",
        "print(len(y_train), len(y_test), len(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kA_aErb27isZ"
      },
      "outputs": [],
      "source": [
        "#зафиксировать seed\n",
        "#страсть к машинному обучению\n",
        "#энергоэффективность оценка\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from brian2 import *\n",
        "\n",
        "# Network Configuration\n",
        "n_input = 11*11  # input layer size\n",
        "n_e = 400  # excitatory neurons\n",
        "n_i = n_e  # inhibitory neurons\n",
        "\n",
        "# Neuron parameters\n",
        "v_rest_e = -65. * mV  # Resting potential for excitatory neurons\n",
        "v_reset_e = -60. * mV  # Reset potential for excitatory neurons\n",
        "v_thresh_e = -52. * mV  # Threshold potential for excitatory neurons\n",
        "v_rest_i = -60. * mV  # Resting potential for inhibitory neurons\n",
        "v_reset_i = -45. * mV  # Reset potential for inhibitory neurons\n",
        "v_thresh_i = -40. * mV  # Threshold potential for inhibitory neurons\n",
        "\n",
        "# STDP Parameters\n",
        "taupre = 20*ms  # Pre-synaptic time constant\n",
        "taupost = taupre  # Post-synaptic time constant matches pre-synaptic\n",
        "gmax = .01  # Maximum synaptic strength\n",
        "dApre = 0.1  # STDP learning rate for pre-synaptic changes\n",
        "dApost = -dApre * taupre / taupost * 1.05   # STDP learning rate for post-synaptic changes\n",
        "dApost *= gmax\n",
        "dApre *= gmax\n",
        "\n",
        "# Synapse strength\n",
        "wi = 3\n",
        "\n",
        "# STDP Synapse Model\n",
        "stdp_model = '''\n",
        "    w : 1\n",
        "    lr1 : 1\n",
        "    lr2 : 1\n",
        "    dApre/dt = -Apre / taupre : 1 (event-driven)\n",
        "    dApost/dt = -Apost / taupost : 1 (event-driven)\n",
        "'''\n",
        "pre = '''\n",
        "    ge += w\n",
        "    Apre += dApre\n",
        "    w = clip(w + lr1*Apost, 0, gmax)\n",
        "'''\n",
        "post = '''\n",
        "    Apost += dApost\n",
        "    w = clip(w + lr2*Apre, 0, gmax)\n",
        "'''\n",
        "\n",
        "\n",
        "class Model():\n",
        "\n",
        "    def __init__(self, debug=False):\n",
        "\n",
        "\n",
        "      reset_e = '''\n",
        "      v = v_reset_e\n",
        "      vt += adaptive * 0.05 *mV  # vt изменяется только если adaptive равно 1\n",
        "      '''\n",
        "\n",
        "      app = {}\n",
        "      app['PG'] = PoissonGroup(n_input, rates=np.zeros(n_input)*Hz, name='PG')\n",
        "\n",
        "      # Excitatory neurons\n",
        "      neuron_e = '''\n",
        "      dv/dt = (ge*(0*mV-v) + gi*(-100*mV-v) + (v_rest_e-v)) / (100*ms) : volt\n",
        "      dvt/dt = adaptive * (v_thresh_e-vt) / (150*ms) : volt\n",
        "      dge/dt = -ge / (1*ms) : 1\n",
        "      dgi/dt = -gi / (2*ms) : 1\n",
        "      adaptive : 1\n",
        "      '''\n",
        "\n",
        "      # Inhibitory neurons\n",
        "      neuron_i = '''\n",
        "      dv/dt = (ge*(0*mV-v) + (v_rest_i-v)) / (1*ms) : volt\n",
        "      dge/dt = -ge / (2*ms) : 1\n",
        "      '''\n",
        "\n",
        "      app['IG'] = NeuronGroup(n_i, neuron_i, threshold='v>v_thresh_i', refractory=2*ms, reset='v=v_reset_i', method='euler', name='IG')\n",
        "      app['IG'].v = v_rest_i - 20.*mV\n",
        "\n",
        "      # input images as rate encoded Poisson generators\n",
        "      app['PG'] = PoissonGroup(n_input, rates=np.zeros(n_input)*Hz, name='PG')\n",
        "\n",
        "      app['EG'] = NeuronGroup(n_e, neuron_e, threshold='v>vt', refractory=5*ms, reset=reset_e, method='euler', name='EG')\n",
        "      app['EG'].v = v_rest_e - 20.*mV\n",
        "      app['EG'].vt = v_thresh_e\n",
        "\n",
        "      # app['EG_1'] = NeuronGroup(n_e, neuron_e, threshold='v>vt', refractory=5*ms, reset=reset_e, method='euler', name='EG_1')\n",
        "      # app['EG_1'].v = v_rest_e - 20.*mV\n",
        "      # app['EG_1'].vt = v_thresh_e\n",
        "\n",
        "        # if (debug):\n",
        "        #     app['ESP'] = SpikeMonitor(app['EG'], name='ESP')\n",
        "        #     app['ESM'] = StateMonitor(app['EG'], ['v'], record=True, name='ESM')\n",
        "        #     app['ERM'] = PopulationRateMonitor(app['EG'], name='ERM')\n",
        "      app['IG'] = NeuronGroup(n_i, neuron_i, threshold='v>v_thresh_i', refractory=2*ms, reset='v=v_reset_i', method='euler', name='IG')\n",
        "      app['IG'].v = v_rest_i - 20.*mV\n",
        "\n",
        "      if (debug):\n",
        "          app['ISP'] = SpikeMonitor(app['IG'], name='ISP')\n",
        "          app['ISM'] = StateMonitor(app['IG'], ['v'], record=True, name='ISM')\n",
        "          app['IRM'] = PopulationRateMonitor(app['IG'], name='IRM')\n",
        "\n",
        "      #   # poisson generators one-to-all excitatory neurons with plastic connections\n",
        "      # for cl in range(len(classes)):\n",
        "      #       # we should have a possibility to independently change learning rate for every class subgroup\n",
        "      #     app[f'S1_{cl}'] = Synapses(app['PG'], app['EG'][cl*100:(cl+1)*100], stdp_model, on_pre=pre, on_post=post, method='euler', name=f'S1_{cl}')\n",
        "      #     app[f'S1_{cl}'].connect()\n",
        "      #     app[f'S1_{cl}'].w = 'rand()*gmax' # random weights initialisation\n",
        "      #     app[f'S1_{cl}'].lr1 = 0.01 # enable stdp\n",
        "      #     app[f'S1_{cl}'].lr2 = 0.0001 # enable stdp\n",
        "\n",
        "      app[f'S1'] = Synapses(app['PG'], app['EG'], stdp_model, on_pre=pre, on_post=post, method='euler', name=f'S1')\n",
        "      app[f'S1'].connect()\n",
        "      app[f'S1'].w = 'rand()*gmax' # random weights initialisation\n",
        "      app[f'S1'].lr1 = 1 # enable stdp\n",
        "      app[f'S1'].lr2 = 1 # enable stdp\n",
        "\n",
        "      # app[f'S4'] = Synapses(app['EG'], app['EG_1'], stdp_model, on_pre=pre, on_post=post, method='euler', name=f'S4')\n",
        "      # app[f'S4'].connect()\n",
        "      # app[f'S4'].w = 'rand()*gmax' # random weights initialisation\n",
        "      # app[f'S4'].lr1 = 0.01 # enable stdp\n",
        "      # app[f'S4'].lr2 = 0.0001 # enable stdp\n",
        "\n",
        "\n",
        "      # excitatory neurons one-to-one inhibitory neurons\n",
        "      app['S2'] = Synapses(app['EG'], app['IG'], 'w : 1', on_pre='ge += w', name='S2')\n",
        "      app['S2'].connect(j='i')\n",
        "      app['S2'].delay = 'rand()*10*ms'\n",
        "      app['S2'].w = wi # very strong fixed weights to ensure corresponding inhibitory neuron will always fire\n",
        "\n",
        "      # inhibitory neurons one-to-all-except-one excitatory neurons\n",
        "      app['S3'] = Synapses(app['IG'], app['EG'], 'w : 1', on_pre='gi += w', name='S3')\n",
        "      app['S3'].connect(condition='i!=j')\n",
        "      app['S3'].delay = 'rand()*5*ms'\n",
        "      app['S3'].w = wi/n_e # weights are selected in such a way as to maintain a balance between excitation and ibhibition\n",
        "\n",
        "      self.net = Network(app.values())\n",
        "      self.net.run(0*second)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        return self.net[key]\n",
        "\n",
        "\n",
        "    def set_adaptive_threshold(self, enable):\n",
        "\n",
        "      if enable:\n",
        "          self.net['EG'].adaptive = 1  # Активируем изменение порога\n",
        "          # self.net['EG_1'].adaptive = 1\n",
        "      else:\n",
        "          self.net['EG'].adaptive = 0  # Активируем изменение порога\n",
        "          # self.net['EG_1'].adaptive = 0\n",
        "\n",
        "\n",
        "    def train(self, X, targets, epoch):\n",
        "\n",
        "        self.set_adaptive_threshold(True)\n",
        "        print(\"we_are_in_train\")\n",
        "        for ep in range(epoch):\n",
        "            print(f'{ep}')\n",
        "            for idx in range(len(X)):\n",
        "                # print(f'{idx}')\n",
        "\n",
        "                yt = int(targets[idx]) # target class\n",
        "\n",
        "                mon_out = SpikeMonitor(self.net['EG'], record=True, name='out_1')\n",
        "                self.net.add(mon_out)\n",
        "\n",
        "                max_firing_rate = 63.75\n",
        "\n",
        "                # # set learning rate for each subgroup of excitatory neurons\n",
        "                # for cl in range(len(classes)):\n",
        "                #     if cl == classes.index(yt):\n",
        "                #         self.net[f'S1_{cl}'].lr1 = 1 # this is regular stdp\n",
        "                #         self.net[f'S1_{cl}'].lr2 = 1\n",
        "                #     else:\n",
        "                #         self.net[f'S1_{cl}'].lr1 = 1  # or 0? this is d-STDP\n",
        "                #         self.net[f'S1_{cl}'].lr2 = 1\n",
        "\n",
        "\n",
        "                # active mode\n",
        "                self.net['PG'].rates = X[idx].ravel()*Hz\n",
        "                self.net.run(0.35*second)\n",
        "\n",
        "                total_spikes = sum(mon_out.count)\n",
        "\n",
        "                # Check if total spikes in the output layer are less than 5\n",
        "                while total_spikes < 5:\n",
        "                  # Increase maximum firing rate by 32 Hz\n",
        "                  max_firing_rate += 32\n",
        "                  # Reassign input firing rates with the updated maximum firing rate\n",
        "                  self.net['PG'].rates = (X[idx].ravel() / 255) * max_firing_rate * Hz\n",
        "                  self.net.run(0.35 * second)\n",
        "                  total_spikes = sum(mon_out.count)\n",
        "\n",
        "                self.net.remove(self.net['out_1'])\n",
        "\n",
        "                # passive mode\n",
        "                self.net['PG'].rates = np.zeros(n_input)*Hz\n",
        "                self.net.run(0.15*second)\n",
        "\n",
        "                # tqdm(range(len(X))) # plot a progress bar\n",
        "\n",
        "\n",
        "    def evaluate(self, X, targets, X_train, targets_train):\n",
        "\n",
        "        self.set_adaptive_threshold(False)\n",
        "\n",
        "        # Отключение STDP\n",
        "        # for cl in range(len(classes)):\n",
        "        self.net['S1'].lr1 = 0  # STDP off\n",
        "        self.net['S1'].lr2 = 0  # STDP off\n",
        "        # self.net['S2'].w = wi/2\n",
        "        # self.net['S3'].w = wi/2\n",
        "        # self.net['S4'].lr1 = 0  # STDP off\n",
        "        # self.net['S4'].lr2 = 0\n",
        "            # self.net[f'S4_{cl}'].lr1 = 0  # STDP off\n",
        "            # self.net[f'S4_{cl}'].lr2 = 0  # STDP off\n",
        "\n",
        "\n",
        "        n_classes = 4\n",
        "        n_neurons = self.net['EG'].N  # Общее количество нейронов в группе EG\n",
        "        class_responses = np.zeros((n_neurons, n_classes))  # Ответы каждого нейрона для каждого класса\n",
        "\n",
        "        for idx in range(len(X_train)):\n",
        "            yt = int(targets_train[idx])\n",
        "\n",
        "            max_firing_rate = 63.75\n",
        "\n",
        "            mon = SpikeMonitor(self.net['EG'], record=True, name='RM')\n",
        "            self.net.add(mon)\n",
        "\n",
        "            self.net['PG'].rates = X_train[idx].ravel() * Hz\n",
        "            self.net.run(0.35 * second)\n",
        "\n",
        "            spike_counts = sum(mon.count)\n",
        "\n",
        "            while spike_counts < 5:\n",
        "\n",
        "                max_firing_rate += 32\n",
        "                self.net['PG'].rates = (X_train[idx].ravel() / 255) * max_firing_rate * Hz\n",
        "                self.net.run(0.35 * second)\n",
        "                spike_counts = sum(mon.count)\n",
        "\n",
        "            spike_counts = mon.count\n",
        "            class_responses[:, yt] += spike_counts  # Добавляем количество спайков каждого нейрона для текущего класса\n",
        "\n",
        "            self.net.remove(mon)\n",
        "\n",
        "        neuron_classes = np.argmax(class_responses, axis=1)\n",
        "        #print(\"Neuron classes:\", neuron_classes)\n",
        "\n",
        "        neuron_classes = np.argmax(class_responses, axis=1)\n",
        "\n",
        "        correct_count = 0\n",
        "\n",
        "        for idx in range(len(X)):\n",
        "\n",
        "            yt = int(targets[idx])\n",
        "            mon = SpikeMonitor(self.net['EG'], record=True, name='RM')\n",
        "            self.net.add(mon)\n",
        "            max_firing_rate = 63.75\n",
        "\n",
        "            self.net['PG'].rates = X[idx].ravel() * Hz\n",
        "            self.net.run(0.35 * second)\n",
        "\n",
        "            spike_counts = sum(mon.count)\n",
        "\n",
        "            while spike_counts < 5:\n",
        "\n",
        "                max_firing_rate += 32\n",
        "                self.net['PG'].rates = (X[idx].ravel() / 255) * max_firing_rate * Hz\n",
        "                self.net.run(0.35 * second)\n",
        "                spike_counts = sum(mon.count)\n",
        "\n",
        "            spike_counts = mon.count\n",
        "            response_classes = neuron_classes[spike_counts > 0]  # Классы нейронов, которые сгенерировали спайки\n",
        "\n",
        "            # Голосование за наиболее часто встречающийся класс\n",
        "            if len(response_classes) > 0:\n",
        "              predicted_class = np.bincount(response_classes).argmax()\n",
        "\n",
        "            if predicted_class == yt:\n",
        "              correct_count += 1\n",
        "\n",
        "            self.net.remove(mon)\n",
        "\n",
        "        accuracy = correct_count / len(X)\n",
        "\n",
        "\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e0TOsBy7lsl",
        "outputId": "55287f72-7f95-4c80-afd6-beee7f6e52d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "we_are_in_train\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "import brian2genn\n",
        "from brian2 import *\n",
        "import brian2.numpy_ as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import time\n",
        "import random\n",
        "from brian2 import *\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import os\n",
        "import brian2genn\n",
        "import numpy as np\n",
        "import random\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def set_seed():\n",
        "    random.seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "set_seed()\n",
        "\n",
        "\n",
        "def train_test(x_train, x_test, y_train, y_test):\n",
        "\n",
        "\n",
        "  for s in range(20):\n",
        "\n",
        "      model = Model()\n",
        "\n",
        "      print(f'{s+1}')\n",
        "\n",
        "      model.train(x_train, y_train, s+1)\n",
        "\n",
        "      accuracy = np.array([])\n",
        "\n",
        "      for f in range(1):\n",
        "        accuracy = np.append(accuracy, model.evaluate(x_test, y_test, x_train, y_train))\n",
        "\n",
        "      append_to_file(f'EPOCH{s+1}, accuracy:{accuracy.mean()}', \"/content/drive/MyDrive/SNN_neuro /SNN_new_new\")\n",
        "      print(f'EPOCH{s+1}, accuracy:{accuracy.mean()}')\n",
        "\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "train_test(x_train, x_test, y_train, y_test)\n",
        "end = time.time()\n",
        "print('SNN time:', end - start)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}